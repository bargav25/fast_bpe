ğŸ“– Reading and splitting corpus from data/TinyStoriesV2-GPT4-train.txt...
ğŸ§© Split into 2717700 chunks.
âš™ï¸ Tokenizing with 16 workers...
ğŸ’¾ Writing 532299551 tokens to output/train_ids.memmap as memmap...
âœ… Done. Config for training:
    dtype: int32
    data_shape: [532299551]
